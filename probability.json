[{"description": "P(A) >= 0 for all events A \n", "title": "probability is greater than 0 for all events", "related": [2, 3], "past": [], "future": [5, 8, 43], "keywords": [""], "type": "axiom", "id": 1}, {"description": "total probability = 1 \n", "title": "total probability = 1", "related": [1, 3], "past": [], "future": [4, 5, 8, 43], "keywords": [""], "type": "axiom", "id": 2}, {"description": "For every infinite sequence of disjoint events A1 ... An the P(union of all events) = sum of all probabilities of events\n", "title": "summation of events = summation of probabilities (addition rule)", "related": [1, 2], "past": [], "future": [4, 6, 7, 8, 9, 10, 48], "keywords": [""], "type": "axiom", "id": 3}, {"description": "P(Ac) = 1 - P(A) \n", "title": "complement of A", "related": [], "past": [2, 3], "future": [], "keywords": ["complement"], "type": "theorem", "id": 4}, {"description": "0 <= P(A) <= 1 \n", "title": "probability is between 0 and 1", "related": [], "past": [1, 2], "future": [131], "keywords": ["probability", "between"], "type": "Theorem 1.5.5", "id": 5}, {"description": "If A in B then Pr(A) <= Pr(B) \n", "title": "Pr(A) <= Pr(B) if A in B", "related": [], "past": [3], "future": [], "keywords": [""], "type": "Theorem 1.5.4", "id": 6}, {"description": "Pr(empty set) = 0 \n", "title": "Pr(empty set) = 0", "related": [], "past": [3], "future": [], "keywords": [""], "type": "Theorem 1.5.1", "id": 7}, {"description": "probability on a sample space S is a specification of numbers Pr(A) for all events that satisfy Axioms 1 2 and 3. \n", "title": "probability", "related": [], "past": [1, 2, 3], "future": [11, 12, 22, 28, 34, 37, 41, 44, 46, 52, 53, 90, 134], "keywords": [""], "type": "definition", "id": 8}, {"description": "for every two events A and B Pr(A intersection Bc) = Pr(A) - Pr(A intersection B) \n", "title": "Pr(A intersection Bc) = Pr(A) - Pr(A intersection B)", "related": [], "past": [3], "future": [10], "keywords": [""], "type": "Theorem 1.5.6", "id": 9}, {"description": "Pr(A union B) = Pr(A) + Pr(B) - Pr(A intersection B) \n", "title": "Pr(A union B) = Pr(A) + Pr(B) - Pr(A intersection B) ", "related": [], "past": [3, 9], "future": [], "keywords": [""], "type": "Theorem 1.5.7", "id": 10}, {"description": "Bonferroni inequality is P(union Ai) <= sum of P(Ai) and P(intersection Ai) >= 1- sum(P(Aic) \n", "title": "Bonferroni inequality", "related": [], "past": [8], "future": [], "keywords": [""], "type": "Theorem", "id": 11}, {"description": "a finite sample space is where S is every outcome is equally likely \n", "title": "simple sample space", "related": [], "past": [8], "future": [], "keywords": [""], "type": "definition", "id": 12}, {"description": "multiplication rule is if a job consists of k parts (k >= 2) and the ith part has ni possible outcomes regardless of what outcomes came before then the job can be done in n1 x n2 x ... x nk ways \n", "title": "multiplication rule", "related": [], "past": [], "future": [14, 15, 16, 17], "keywords": [""], "type": "definition", "id": 13}, {"description": "ordered samples without replacement is n", "title": "ordered samples without replacement", "related": [15, 16, 17], "past": [13], "future": [], "keywords": [""], "type": "definition", "id": 14}, {"description": "unordered samples without replacement is Cnk = (n k) = n", "title": "unordered samples without replacement", "related": [14, 16, 17], "past": [13], "future": [18, 20], "keywords": [""], "type": "definition", "id": 15}, {"description": "ordered samples with replacement is just n^k \n", "title": "ordered samples with replacement", "related": [14, 15, 17], "past": [13], "future": [], "keywords": [""], "type": "definition", "id": 16}, {"description": "unordered samples with replacement is (n+k-1 k) \n", "title": "unordered samples with replacement", "related": [14, 15, 16], "past": [13], "future": [], "keywords": [""], "type": "definition", "id": 17}, {"description": "binomial coefficient is the number of ways to choose k items out of n without replacement. (n k) = n", "title": "binomial coefficient", "related": [20, 21], "past": [15], "future": [19, 39], "keywords": [""], "type": "definition", "id": 18}, {"description": "binomial theorem is (x+y)^n = sum[n k](n k)x^k * y^(n-k) \n", "title": "binomial theorem", "related": [20, 21], "past": [18], "future": [39], "keywords": [""], "type": "definition", "id": 19}, {"description": "multinomial coefficient is number of ways to divide n items into k different groups or (n n1...nk) = n", "title": "multinomial coefficient", "related": [18, 19], "past": [15], "future": [21], "keywords": [""], "type": "definition", "id": 20}, {"description": "multinomial theorem is (x1 + x2 + ... xk)^n = sum[n1...nk = n](n n1...nk)x1^n1 * x2^n2 * ... * xk^nk \n", "title": "multinomial theorem", "related": [19, 18], "past": [20], "future": [], "keywords": [""], "type": "definition", "id": 21}, {"description": "conditional probability of event A given that event B has occured is P(A|B) = P(A intersection B)/P(B) if P(B) > 0 \n", "title": "conditional probability", "related": [], "past": [8], "future": [23, 26, 27, 29, 61, 102], "keywords": [""], "type": "definition", "id": 22}, {"description": "Pr(A|B) is computed as the proportion of total probability Pr(B) that is represented by Pr(A intersection B). intuitively the proportion of B that is also part of A \n", "title": "the proportion of B that is also part of A", "related": [], "past": [22], "future": [], "keywords": [""], "type": "implication", "id": 23}, {"description": "partition is for S a sample space A1 ... Ak are disjoint and U[i infinity]Ai = S then the collection A1 A2 ... is called the partition of S \n", "title": "partition", "related": [], "past": [25], "future": [26, 27], "keywords": [""], "type": "definition", "id": 24}, {"description": "sample space S \n", "title": "sample space S", "related": [], "past": [], "future": [24, 34], "keywords": [""], "type": "definition", "id": 25}, {"description": "law of total probability states that if B1...Bk forma  partition of the sample space S and P(Bj) > 0 for all j then for every event A in S: P(A) = sum[j=1 k] P(Bj)P(A|Bj) \n", "title": "law of total probability", "related": [], "past": [24, 22], "future": [27, 103], "keywords": [""], "type": "Theorem 2.1.4", "id": 26}, {"description": "Bayes' Theorem states that if B1...Bk form a partition of S and P(Bj) > 0 for all j and P(A) > 0 then P(Bi|A) = P(Bi)P(A|Bi)/sum[j=1 k]P(Bj)P(A|Bj). The denomiator can also be written as P(A). The numerator is equal to P(Bi intersection A) \n", "title": "Bayes' Theorem", "related": [], "past": [22, 24, 26], "future": [], "keywords": [""], "type": "Theorem 2.3.1", "id": 27}, {"description": "independence states that two events A and B are said to be statistically inindependent then P(A| intersection B) = P(A) * P(B) \n", "title": "independent events", "related": [], "past": [8], "future": [29, 30, 31, 59], "keywords": [""], "type": "definition", "id": 28}, {"description": "consequence of independence of A and B then P(A|B) = P(A intersection B)/P(B) = P(A)P(B)/P(B) = P(A). As well as P(B |A) = P(B) \n", "title": "conditional probabilities for independent events are just probabilities", "related": [], "past": [22, 28], "future": [], "keywords": [""], "type": "implication", "id": 29}, {"description": "if A and B are independent then A and Bc or Ac and B or Ac and Bc are all indpependent as well \n", "title": "complements are independent", "related": [], "past": [28], "future": [], "keywords": [""], "type": "theorem", "id": 30}, {"description": "mutually independent events are when A1...Ak if for every subset Ai1 ... Aij j = 2...k then P(Ai1 intersection ... Aij) = P(Ai1) x ... x P(Aij) \n", "title": "mutually independent events", "related": [], "past": [28], "future": [32, 33], "keywords": [""], "type": "definition", "id": 31}, {"description": "P(A inter B inter C) = P(A)P(B)P(C) does not imply mutual independence. Pairwise independence does not imply mutual independence \n", "title": "mutual independence is not", "related": [], "past": [31], "future": [], "keywords": [""], "type": "implication", "id": 32}, {"description": "conditional independence given B is for every subset Ai1...Aij of A1...Ak then P(Ai1 intersection ... Aij|B) = P(Ai1|B) x ... x P(Aij|B) \n", "title": "conditional independence", "related": [], "past": [31], "future": [], "keywords": [""], "type": "definition", "id": 33}, {"description": "random variable is a function from a sample space S to the real numbers R. P(X = xi) = P({sj in S: X(sj) = xi} where xi in A \n", "title": "random variable", "related": [], "past": [25, 8], "future": [35, 36, 40, 51, 52, 53, 59, 61, 63, 66, 69, 70, 71, 86, 87, 109, 134], "keywords": [""], "type": "definition", "id": 34}, {"description": "support of X is the range of X \n", "title": "support of random variable", "related": [], "past": [34], "future": [], "keywords": [""], "type": "definition", "id": 35}, {"description": "random variable X is said to have a discrete distribution if X can only take countable number of different values \n", "title": "discrete random variable", "related": [40], "past": [34], "future": [37, 110], "keywords": [""], "type": "definition", "id": 36}, {"description": "probability mass function is defined as f(x) = P(X=x) defined for all x in R.  ", "title": "probability mass function", "related": [41], "past": [8, 36], "future": [38, 39, 43, 44, 51, 53, 57, 60, 72, 73, 110, 112], "keywords": [], "type": "definition", "id": 37}, {"description": "Bernoulli distribution with parameter p is X ~ Bernoulli(p) then the pmf is f(x) = p, if x=1 : 1-p, if x = 0 : 0, otherwise. X = 0 if loss and X = 1 if win ", "title": "Bernoulli distribution with parameter p", "related": [], "past": [37], "future": [107, 109, 112, 113], "keywords": [], "type": "definition", "id": 38}, {"description": "binomial distribution if X is number of successes in n independent trials where the probability of success is p. Then P(X=x) = (n k)p^x * (1-p)^(n-x) x = 0,1,...,n. X ~ Binomial(n,p) ", "title": "Binomial distribution with parameters n and p", "related": [], "past": [37, 18, 19, 107], "future": [108, 110], "keywords": [], "type": "definition", "id": 39}, {"description": "continuous random variables ", "title": "continuous random variables", "related": [36], "past": [34], "future": [41, 67, 68], "keywords": [], "type": "definition", "id": 40}, {"description": "probability density function or pdf is a non-negative function from continuous random variable X where f defined on real line is P(x1 <= X <= x2) = int[x1,x2]f(x)dx ", "title": "probability density function", "related": [37], "past": [40, 8], "future": [42, 43, 44, 51, 53, 55, 57, 60, 66, 68, 69, 70, 71, 72, 73, 82], "keywords": [], "type": "definition", "id": 41}, {"description": "uniform distribution is f(x) = 1/(b-a) for x in [a,b]. X~Uniform(a,b) ", "title": "uniform distribution", "related": [], "past": [41], "future": [67, 130], "keywords": [], "type": "definition", "id": 42}, {"description": "a pdf of a random variable holds iff both f(x) >= 0 and sum(1 infinity)[f(xi)] = 1 and int(-inf inf)[f(x)dx] = 1  ", "title": "probability density function has f(x)>=0 and sum of all = 1", "related": [], "past": [41, 37, 2, 1], "future": [], "keywords": [], "type": "theorem", "id": 43}, {"description": "cumulative distribution function is F(x) = P(X<=x) for all x ", "title": "cumulative distribution function", "related": [], "past": [8, 41, 37], "future": [45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 58, 67, 128], "keywords": [], "type": "definition", "id": 44}, {"description": "F(x) = int(-inf x)[f(u)du or F(xi) = sum(u<=xi)[f(u)] ", "title": "F(x) = int(-inf x)[f(u)du or F(xi) = sum(u<=xi)[f(u)]", "related": [], "past": [44], "future": [56, 57], "keywords": [], "type": "definition", "id": 45}, {"description": "a function F(x) is a cdf iff lim(x->inf)F(x) = 0 and lim(x->-inf)F(x) = 1, F(x) is a nondecreasing function of x, F(x) is right-continuous; lim(x->x0)F(x) = F(x0) ", "title": "function is a cdf if the following hold", "related": [], "past": [44, 8], "future": [], "keywords": [], "type": "theorem", "id": 46}, {"description": "for every value x Pr(X>x) = 1-F(x) ", "title": "Pr(X>x) = 1-F(x)", "related": [], "past": [44], "future": [], "keywords": [], "type": "Theorem 3.3.1", "id": 47}, {"description": "Pr(x1 < X <= x2) = F(x2) - F(x1) ", "title": "Pr(x1 < X <= x2) = F(x2) - F(x1)", "related": [], "past": [3, 44], "future": [], "keywords": [], "type": "Theorem 3.3.2", "id": 48}, {"description": "Pr(X<x) = F(x-) ", "title": "Pr(X<x) = F(x-)", "related": [], "past": [44], "future": [50], "keywords": [], "type": "Theorem 3.3.3", "id": 49}, {"description": "Pr(X = x) = F(x) - F(x-) ", "title": "Pr(X = x) = F(x) - F(x-)", "related": [], "past": [49, 44], "future": [], "keywords": [], "type": "Theorem 3.3.4", "id": 50}, {"description": "identically distributed if for every set A we have P(X in A) = P(Y in A) for random variables X and Y ", "title": "identically distributed", "related": [], "past": [34, 37, 41, 44], "future": [], "keywords": [], "type": "definition", "id": 51}, {"description": "quantile function is with X random variable and cdf F(x) and let p in (0,1): F-1(p) = the smallest x such that F(x) >= p. if continuous and one-to-one then  there is only one x such that F(x) = p ", "title": "quantile function", "related": [], "past": [34, 44, 8], "future": [67], "keywords": [], "type": "definition", "id": 52}, {"description": "the joint distribution or bivariate distribution of X and Y is the collection of all probabilities of the form Pr[(X,Y) in C] for all sets C of pairs of real numbers such that {(X,Y) in C} is an event ", "title": "joint distribution", "related": [], "past": [8, 37, 41, 34], "future": [54, 56, 57, 61, 91], "keywords": [], "type": "definition", "id": 53}, {"description": "joint cumulative distribution function of two random variables is F(x,y) = P(X<=x, Y<=y) for all x, y in X, Y ", "title": "joint cumulative distribution", "related": [], "past": [53, 44], "future": [56, 58], "keywords": [], "type": "definition", "id": 54}, {"description": "dF(x)/dx = p(x) ", "title": "dF(x)/dx = p(x)", "related": [], "past": [44, 41], "future": [56], "keywords": [], "type": "definition", "id": 55}, {"description": "F(x,y) = d2F(x,y)/dxdy ", "title": "F(x,y) = d2F(x,y)/dxdy", "related": [], "past": [55, 54, 53, 45], "future": [], "keywords": [], "type": "definition", "id": 56}, {"description": "marginal pdfs are fx(x) = P(X = x) = sum/int[f(x,y)] over all y. similarly for fy(y) = sum over all x in joint distribution ", "title": "marginal distribution", "related": [], "past": [53, 41, 37, 45], "future": [58, 60, 61, 62], "keywords": [], "type": "definition", "id": 57}, {"description": "marginal cdf is the lim(y->inf)F(x,y) = Fx(x). similarly for Fy(y) ", "title": "marginal cumulative distribution", "related": [], "past": [54, 44, 57], "future": [], "keywords": [], "type": "definition", "id": 58}, {"description": "independent random variables if for every two sets A and B in R the events {s: X(s) in A} and {s: Y(s) in B} are independent ", "title": "independent random variables", "related": [], "past": [28, 34], "future": [60, 62, 72, 77, 96, 97], "keywords": [], "type": "indepedence", "id": 59}, {"description": "two random variables X and Y with joint pf/pdf f(x,y) and marginal pf's/pdf's fx(x) and fy(y) are independent iff f(x,y) = fx(x)fy(y) ", "title": "marginal pdfs multiplied give joint distribution if independent", "related": [], "past": [59, 57, 37, 41], "future": [], "keywords": [], "type": "theorem", "id": 60}, {"description": "f(x|y) = f(x,y)/fy(y) is called the conditional pf/pdf of X given Y = y ", "title": "conditional probability distribution function", "related": [], "past": [57, 53, 22, 34], "future": [62, 127], "keywords": [], "type": "definition", "id": 61}, {"description": "random variables X and Y are independent iff f(x|y) = fx(x) ", "title": "conditional probability indicates independence", "related": [], "past": [57, 61, 59], "future": [], "keywords": [], "type": "theorem", "id": 62}, {"description": "if X is a random variable then any function of X, g(X), is also a random variable ", "title": "transformation of random variable", "related": [], "past": [34], "future": [64, 67, 68, 70, 72, 74], "keywords": [], "type": "definition", "id": 63}, {"description": "inverse mapping is defined as g^-1(A) = {x in X:g(x) in A} ", "title": "inverse mapping ", "related": [], "past": [63], "future": [65, 67], "keywords": [], "type": "definition", "id": 64}, {"description": "we can write P(Y in A) = P(g(X) in A) = P({x in X:g(x) in A}) = P(X in g-1(A)) ", "title": "inverse mapping in terms of X", "related": [], "past": [64], "future": [], "keywords": [], "type": "definition", "id": 65}, {"description": "exponential distribution X ~ Exp(l) = lexp(-lx), x > 0 ", "title": "exponential distribution X ~ Exp(l)", "related": [], "past": [34, 41], "future": [126, 127, 128], "keywords": [], "type": "distribution", "id": 66}, {"description": "let X have continuous cdf F and let Y = F(X). Then F(X) ~ Uniform(0,1). if Y ~Uniform(0,1) and F is continuous cdf with quantile function F^-1 then X = F-1(Y) has cdf F ", "title": "probability integral transformation", "related": [], "past": [44, 40, 63, 42, 64, 52], "future": [], "keywords": [], "type": "Theorem 3.8.3", "id": 67}, {"description": "let x be a random variable with pdf fx(x) and let Y = g(X) where g iis a monotone function. Suppose fx(x) is continuous on X and that g-1(y) has a continuous derivative on Y = {y:y=g(x), x in X}. Then the pdf of Y is fy(y) = fx(g-1(y))|d(g-1(y))/dy| for y in Y. ", "title": "monotone transformations of continuous random variable", "related": [], "past": [63, 40, 41], "future": [70], "keywords": [], "type": "theorem", "id": 68}, {"description": "Gamma distribution X ~ Gamma(n, b) has pdf f(x) = 1/(n-1)!b^n * x^(n-1) * e^-x//b ", "title": "Gamma distribution X ~ Gamma (n,b)", "related": [], "past": [41, 34, 124], "future": [125, 126], "keywords": [], "type": "distribution", "id": 69}, {"description": "Let X be a random variable with pdf fx(x) and let Y = aX + b, a does not equal 0. Then fy(y) = 1/|a| * f((y-b)/a). ", "title": "linear transformation of random variable", "related": [], "past": [68, 63, 41, 34], "future": [115], "keywords": [], "type": "corollary", "id": 70}, {"description": "Normal distribution with parameters u and variance are have notation X ~ N(u, sigma^2). fx(x) = 1/(sigma)(2pi)^2 * exp(-(x-u)^2/2(sigma)^2) ", "title": "Normal distribution X ~ Norm (u, sigma^2)", "related": [], "past": [34, 41, 73], "future": [115, 116, 117, 118, 119, 120, 121, 122], "keywords": [], "type": "distribution", "id": 71}, {"description": "convolution is X1 and X2 be independent continuous random variables and let Y  = X1 + X2. The distribution of Y is g(y) = int(-inf, inf)[f1(y-t)f2(t)dt if X1 and X2 are independent ", "title": "convolution of independent random variables", "related": [], "past": [59, 63, 41, 37], "future": [], "keywords": [], "type": "definition", "id": 72}, {"description": "expected value or mean is E(X) is int(-int, inf)[xf(x)dx] ", "title": "expectation or mean", "related": [], "past": [37, 41, 80], "future": [71, 74, 75, 76, 77, 78, 83, 86, 91, 102, 103, 116, 132], "keywords": [], "type": "definition", "id": 73}, {"description": "E[g(X)] = int(-inf, inf)[g(x)f(x)dx] ", "title": "E[g(X)] = int(-inf, inf)[g(x)f(x)dx] expectation of g(X) a function of X", "related": [], "past": [73, 63], "future": [], "keywords": [], "type": "Theorem 4.1.1", "id": 74}, {"description": "properties of expectation are that it is linear. E(aX+b) = aE(X) + b and let E[sum(n)[Xi]] = sum(n)[E[Xi]], as well as products if independent. ", "title": "properties of expectation are linear", "related": [], "past": [73], "future": [77, 96], "keywords": [], "type": "implication", "id": 75}, {"description": "variance is with finite mean u is Var(X) = E((X-u)^2) and sigma = (Var(X))^.5. E(X^2) - E(X)^2 = Var(X) ", "title": "variance", "related": [], "past": [73, 81], "future": [77, 79, 85, 91, 92, 99, 101, 105, 106, 116], "keywords": [], "type": "definition", "id": 76}, {"description": "properties of the variance include Var(X) >= 0, Var(X) = 0 iff X is a constant. Var(aX + b) = a^2Var(X). If X1,...,Xn are independent we have Var(sum(n)[Xi]) = sum(n)[Var(Xi)] ", "title": "properties of the variance", "related": [], "past": [75, 73, 76, 59], "future": [101], "keywords": [], "type": "definition", "id": 77}, {"description": "mean is a measure of location ", "title": "mean is a measure of location", "related": [], "past": [73], "future": [], "keywords": [], "type": "implication", "id": 78}, {"description": "variance is a measure of scale ", "title": "variance is a measure of scale", "related": [], "past": [76], "future": [], "keywords": [], "type": "implication", "id": 79}, {"description": "E(X^k) is called the kth moment of X ", "title": "kth moment of X", "related": [], "past": [], "future": [73, 87], "keywords": [], "type": "definition", "id": 80}, {"description": "E(X) = u, then E((X-u)^k) is called the kth central moment of X ", "title": "kth central moment of X", "related": [], "past": [], "future": [76, 84, 85], "keywords": [], "type": "definition", "id": 81}, {"description": "symmetric distribution is symmetric with respect to point x0 if f(x0 + d) = ff - f(x0 - d) for all d ", "title": "symmetric distribution", "related": [], "past": [41], "future": [83, 84], "keywords": [], "type": "definition", "id": 82}, {"description": "if the mean of a symmetric distribution exists, then it is the point of symmetry ", "title": "mean is the point of symmetry", "related": [], "past": [82, 73], "future": [], "keywords": [], "type": "implication", "id": 83}, {"description": "if the distribution of X is symmetric, then wrt its mean u, then E((X-u)^k) = 0 for k odd ", "title": "odd kth central moment = 0 for symmetric distributions", "related": [], "past": [81, 82], "future": [], "keywords": [], "type": "implication", "id": 84}, {"description": "skewness is measured as E((X-u)^3)/sigma^3 ", "title": "skewness", "related": [], "past": [76, 81], "future": [], "keywords": [], "type": "definition", "id": 85}, {"description": "moment generating function is = E[e^(tX)] for all t in R ", "title": "moment generating function", "related": [], "past": [73, 34], "future": [87, 88, 89, 111, 115, 122], "keywords": [], "type": "definition", "id": 86}, {"description": "Let X be a random variable whose moment generating function is finite for t in  an open interval around zero. Then the nth moment of X is finite, and E[X^n] = dn/dtn (m.g.f(t)) at t = 0.  ", "title": "nth moment of X is nth derivative of moment generating function", "related": [], "past": [80, 86, 34], "future": [], "keywords": [], "type": "Theorem 4.4.2", "id": 87}, {"description": "psi_aX+b(t) = e^bt * psi_X(at), and if independent, psi_y(t) = prod(n)[psi_i(t)] ", "title": "properties of the moment generating function", "related": [], "past": [86], "future": [115], "keywords": [], "type": "theorem", "id": 88}, {"description": "uniqueness of m.g.f. is if m.g.f. are finite and psi_X(t) = psi_Y(t) for all values of t, then X and Y have the same distribution ", "title": "uniqueness of moment generating function", "related": [], "past": [86], "future": [111, 115], "keywords": [], "type": "Theorem 4.4.5", "id": 89}, {"description": "median is when P(X<=m) >= 0.5 and P(X>=m) >=0.5 for every number m = median ", "title": "median", "related": [], "past": [8], "future": [], "keywords": [], "type": "definition", "id": 90}, {"description": "covariance is defined as Cov(X,Y) = E((X-ux)(Y-uy)). Cov(X,Y) = E(XY) - E(X)E(Y) ", "title": "covariance", "related": [], "past": [73, 76, 53], "future": [92, 93, 96, 99, 100, 101], "keywords": [], "type": "expectation", "id": 91}, {"description": "correlation is defined as Cor(X,Y) = Cov(X,Y)/sigma_x)(sigma_y) ", "title": "correlation", "related": [], "past": [91, 76], "future": [94, 95, 98], "keywords": [], "type": "definition", "id": 92}, {"description": "covariance is how much X and Y depend on each other linearly ", "title": "covariance is how much X and Y depend on each other linearly ", "related": [], "past": [91], "future": [95, 98], "keywords": [], "type": ["definition"], "id": 93}, {"description": "correlation is values between -1 <= p <= 1 by the Schwarz Inequality ", "title": "correlation is values between -1 <= p <= 1 by the Schwarz Inequality ", "related": [], "past": [92], "future": [98], "keywords": [], "type": ["definition"], "id": 94}, {"description": "correlation is independent of scale of X and Y ", "title": "correlation is independent of scale of X and Y ", "related": [], "past": [93, 92], "future": [], "keywords": [], "type": ["definition"], "id": 95}, {"description": "if X and Y are independent, Cov(X,Y) = 0 ", "title": "if X and Y are independent, Cov(X,Y) = 0 ", "related": [], "past": [59, 75, 91], "future": [97], "keywords": [], "type": ["definition"], "id": 96}, {"description": "the opposite is not true as two random variables can be uncorrelated without being independent ", "title": "the opposite is not true as two random variables can be uncorrelated without being independent ", "related": [], "past": [96, 59], "future": [], "keywords": [], "type": ["definition"], "id": 97}, {"description": "if Y is a linear function of X, then X and Y are perfectly correlated, p(X,Y) = +-1 ", "title": "if Y is a linear function of X, then X and Y are perfectly correlated, p(X,Y) = +-1 ", "related": [], "past": [92, 94, 93], "future": [], "keywords": [], "type": ["definition"], "id": 98}, {"description": "Cov(X,X) = Var(X) ", "title": "Cov(X,X) = Var(X) ", "related": [], "past": [91, 76], "future": [], "keywords": [], "type": ["definition"], "id": 99}, {"description": "Cov(aX+b, cY+d) = acCov(X,Y) ", "title": "Cov(aX+b, cY+d) = acCov(X,Y) ", "related": [], "past": [91], "future": [], "keywords": [], "type": ["definition"], "id": 100}, {"description": "Var(aX + bY + c) = a^2(Var(X) + b^2(Var(Y)) + 2abCov(X,Y) ", "title": "Var(aX + bY + c) = a^2(Var(X) + b^2(Var(Y)) + 2abCov(X,Y) ", "related": [], "past": [77, 76, 91], "future": [], "keywords": [], "type": ["definition"], "id": 101}, {"description": "the conditional expectation of Y given X = x, denoted E(Y|x) or E(Y|X=x), is the mean of the conditional distribution of Y given X = x. E(Y|x) = int(all inf)[yf(y|x)dy ", "title": "conditional expectation", "related": [], "past": [73, 22], "future": [103, 104, 105, 106], "keywords": [], "type": ["definition"], "id": 102}, {"description": "law of total probability for expectations is E(E(Y|X)) = E(Y) ", "title": "law of total probability for expectations is E(E(Y|X)) = E(Y) ", "related": [], "past": [102, 73, 26, 104], "future": [], "keywords": [], "type": ["definition"], "id": 103}, {"description": "E(Y|X) is a random variable of E(Y|X = x) ", "title": "E(Y|X) is a random variable of E(Y|X = x) ", "related": [], "past": [102], "future": [103], "keywords": [], "type": ["definition"], "id": 104}, {"description": "conditional variance is E((Y-E(Y|x))^2|x) = Var(Y|x) ", "title": "conditional variance is E((Y-E(Y|x))^2|x) = Var(Y|x) ", "related": [], "past": [102, 76], "future": [106], "keywords": [], "type": ["definition"], "id": 105}, {"description": "law of total probability for variance is E[Var(Y|X)] + Var[E(Y|X)] = Var(Y) ", "title": "law of total probability for variance is E[Var(Y|X)] + Var[E(Y|X)] = Var(Y) ", "related": [], "past": [102, 105, 76], "future": [], "keywords": [], "type": ["definition"], "id": 106}, {"description": "sum of Bernoulli variables is Binomial distribution ", "title": "sum of Bernoulli variables is Binomial distribution ", "related": [], "past": [38], "future": [39], "keywords": [], "type": ["definition", "implication"], "id": 107}, {"description": "sum of Binomial variables B(n,p) is B(sum[n], p) ", "title": "sum of Binomial variables B(n,p) is B(sum[n], p) ", "related": [], "past": [39], "future": [], "keywords": [], "type": ["implication"], "id": 108}, {"description": "hypergeometric distribution is sampling without replacement with Bernoulli trials. This can be thought of a sum of dependent Bernoulli trials. see pf  ", "title": "hypergeometric distribution", "related": [], "past": [38, 34], "future": [], "keywords": [], "type": ["distribution", "definition"], "id": 109}, {"description": "Poisson distribution is modeling consecutive arrivals for each interval of time, where the parameter l = np.  ", "title": "Poisson distribution with parameter l", "related": [], "past": [39, 36, 37], "future": [111, 128], "keywords": [], "type": ["distribution", "definition"], "id": 110}, {"description": "sum of Poisson variables has Poisson distribution with mean sum[li] ", "title": "sum of Poisson variables has Poisson distribution with mean sum[li] ", "related": [], "past": [89, 86, 110], "future": [], "keywords": [], "type": ["implication"], "id": 111}, {"description": "Geometric distribution is the number of failures before first success ", "title": "Geometric distribution with parameter p", "related": [], "past": [38, 37], "future": [114], "keywords": [], "type": ["definition", "distribution"], "id": 112}, {"description": "Negative Binomial distribution with parameters r and p if it is the number of failures before the rth success ", "title": "Negative Binomial distribution with parameters r and p", "related": [], "past": [38, 114], "future": [], "keywords": [], "type": ["definition", "distribution"], "id": 113}, {"description": "sum of Geometric(p) variables is NegBinomial(r,p) ", "title": "sum of Geometric(p) variables is NegBinomial(r,p) ", "related": [], "past": [112], "future": [113], "keywords": [], "type": ["implication"], "id": 114}, {"description": "linear transformations of normal distributions are normal distributions ", "title": "linear transformations of normal distributions are normal distributions ", "related": [], "past": [70, 89, 86, 71, 88], "future": [117, 118], "keywords": [], "type": ["implication"], "id": 115}, {"description": "standard normal distribution has mean 0 and variance 1 ", "title": "standard normal distribution has mean 0 and variance 1 ", "related": [], "past": [71, 73, 76], "future": [117], "keywords": [], "type": ["definition"], "id": 116}, {"description": "F(x) = cdf of norm(x-u/sigma) ", "title": "F(x) = cdf of norm(x-u/sigma) ", "related": [], "past": [116, 115, 71], "future": [], "keywords": [], "type": ["definition"], "id": 117}, {"description": "linear combinations of normals are normal distributions ", "title": "linear combinations of normals are normal distributions ", "related": [], "past": [115, 71], "future": [120], "keywords": [], "type": ["definition", "implication"], "id": 118}, {"description": "sample mean is 1/n sum(n)[Xi] ", "title": "sample mean", "related": [], "past": [71], "future": [120], "keywords": [], "type": ["definition"], "id": 119}, {"description": "sample mean is a normal distribution ", "title": "sample mean is a normal distribution ", "related": [], "past": [71, 119, 118], "future": [], "keywords": [], "type": ["definition"], "id": 120}, {"description": "lognormal distribution is log( X) = N(u, sigma^2) ", "title": "lognormal distribution", "related": [], "past": [71], "future": [], "keywords": [], "type": ["definition"], "id": 121}, {"description": "moment generating function of lognormal is just E(X^t) ", "title": "moment generating function of lognormal is just E(X^t) ", "related": [], "past": [86, 71], "future": [], "keywords": [], "type": ["definition"], "id": 122}, {"description": "gamma function is g(a) = int[0,inf](x^(a-1)*e^-x) ", "title": "gamma function", "related": [], "past": [], "future": [124, 129], "keywords": [], "type": ["definition"], "id": 123}, {"description": "int[0,inf](x^(a-1)*e^-bx) = g(a)/b^a ", "title": "int[0,inf](x^(a-1)*e^-bx) = g(a)/b^a ", "related": [], "past": [123], "future": [69, 125], "keywords": [], "type": ["definition"], "id": 124}, {"description": "moments of the gamma function are g(a+k)/(b^k * g(a)) = E(X^k) ", "title": "moments of the gamma function are g(a+k)/(b^k * g(a)) = E(X^k)", "related": [], "past": [69, 124], "future": [], "keywords": [], "type": ["definition"], "id": 125}, {"description": "Gamma(1, b) is Expo(b) ", "title": "Gamma(1, b) is Expo(b)", "related": [], "past": [66, 69], "future": [], "keywords": [], "type": ["implication"], "id": 126}, {"description": "Let X have the exponential distribution with parameter \u03b2, and let t > 0. Then for every number h>0, Pr(X>=t+h|X>=t) = Pr(X>=h) ", "title": "memoryless property of the exponential distribution", "related": [], "past": [66, 61], "future": [], "keywords": [], "type": ["implication"], "id": 127}, {"description": "Times between Arrivals in a Poisson Process. Suppose that arrivals occur according to a Poisson process with rate \u03b2. Let Zk be the time until the kth arrival for k = 1, 2, . . . . Define Y1 = Z1 and Yk = Zk \u2212 Zk\u22121 for k \u2265 2. Then Y1, Y2, . . . are i.i.d. and they each have the exponential distribution with parameter \u03b2. ", "title": "Times between arrivals in a Poisson process", "related": [], "past": [110, 44, 66], "future": [], "keywords": [], "type": ["theorem"], "id": 128}, {"description": "beta distribution with parameters a and b if it has pdf g(a+b)/g(a)g(b) * x^(a-1)(1-x)^(b-1) for 0 < x < 1 ", "title": "Beta distribution with parameters a and b", "related": [], "past": [123], "future": [130, 131], "keywords": [], "type": ["definition", "distribuiton", "distribution"], "id": 129}, {"description": "Beta(1,1) = Uniform(0,1) ", "title": "Beta(1,1) = Uniform(0,1) ", "related": [], "past": [42, 129], "future": [], "keywords": [], "type": ["implication"], "id": 130}, {"description": "prior distributions for probability parameters the beta distribution ", "title": "prior distributions for probability parameters the beta distribution ", "related": [], "past": [129, 5], "future": [], "keywords": [], "type": ["definition"], "id": 131}, {"description": "markov's inequality ", "title": "markov's inequality ", "related": [], "past": [73], "future": [133], "keywords": [], "type": ["definition"], "id": 132}, {"description": "chebyshev inequality ", "title": "chebyshev inequality ", "related": [], "past": [132], "future": [135], "keywords": [], "type": ["definition"], "id": 133}, {"description": "convergence in probability is a sequence Z1,Z2,... of random variables converges to b in probability if for every number e > 0 lim[n->inf] Pr(|Zn-b|<e) = 1 ", "title": "convergence in probability", "related": [], "past": [34, 8], "future": [135], "keywords": [], "type": ["definition"], "id": 134}, {"description": "law of large numbers says for X1,...,Xn form a distribution for which the mean is u and variance is finite. sample mean will converge to u ", "title": "law of large numbers", "related": [], "past": [133, 134], "future": [136], "keywords": [], "type": ["Theorem 6.2.4"], "id": 135}, {"description": "normal distribution is easy for interpretation and analysis ", "title": "normal distribution is easy for interpretation and analysis ", "related": [], "past": [135, 71], "future": [], "keywords": [], "type": ["implication"], "id": 136}]